---
title: "MultiDimensionality Assessment"
output: html_notebook
---



### Number of multidimensional-scales:
1) 3 (mirrors FAMCAT Applied Cognition subdomains)
2) 5 (mirrors hypothesized HoPE Cognition subdomains)

###	Magnitude of scale intercorrelations
1) r’s ranging from 0 to 0.2 
2) r’s ranging from 0.2 to 0.5
3) r’s ranging from 0.5 to 0.7
4) r’s ranging from 0.7 to 0.9

### Bank Design:
1) Peaked Information (skewed and leptokurtic)
2) Flat/ideal Information

### IRT Scoring Methods:
MAP (need to use prior for pickles to pickles)


### CAT Administration:
1) Seq. Unidim SE Stopping (stop administration scale by scale)
2) Determinant of Fisher information matrix (MD-CAT) - chun’s psychometrika paper - item selection & termination

### Sample Size for Calibration:
1) N=300
2) N=500
3) N=750
4) N=1,000

### Sample Size for CAT:
1) Uniform across theta
2) N=1,000 distributed across -3 to 3 by 0.5 theta increments
3) Population that mimics HoPE patients (mildly to severely impaired population TBD)


### Item Parameters:
A) Discrimination: U[1.1, 2.8] - one param per dimension
B) Difficulty: U[-2,-0.67]; U[-0.67, 0.67]; U[0.67, 2] - >0.5 between thresholds


### Outcome Evaluation Criteria:
1) Number of items ‘saved’ = UD-CAT length - MD-CAT length 
2) Recovery of Item parameters, person parameters via CAT & between-item interscale correlation

```{r setup}
#install packages

#install.packages("MASS")
library(MASS)

#install.packages("mirt")
library(mirt)

#install.packages("psych")
library(psych)

# install.packages("mirtCAT")
# library(mirtCAT)

source("CalcInfo.R")
source("CalcRespProb.R")

```


```{r sim}

#design elements
dimensions=c(3,5)

#number of items in each dimension
ni_dim=50

intercorrmag=list(
            "0-0.2"=c("upper"=0.0, "lower"=0.2),
            "0.2-0.5"=c("upper"=0.2, "lower"=0.5),
            "0.5-0.7"=c("upper"=0.5, "lower"=0.7),
            "0.7-0.9"=c("upper"=0.7, "lower"=0.9))

bankinfoshape=c("flat","leptokurtic","skewed")

calbsamplesize=c(300,500,750,1000)

design_conditions=expand.grid(
  "dimensions"=dimensions, 
  "intercorrmag"=names(intercorrmag), 
  "bankinfoshape"=bankinfoshape, 
  "calbsamplesize"=calbsamplesize)


######################################################################################
itempool=t(replicate(100000,{
    difficulties=c(-3,-1.5,1.5,3)
    while(any(diff(difficulties)>0.5)){
      difficulties=sort(sample(seq(-3,3,0.01),4))}
    names(difficulties)=paste0("cb",1:length(difficulties))
    item=c("a"=sample(seq(1.1,2.8,0.01),1),difficulties,"NCAT"=length(difficulties)+1)
    info=sapply(seq(-3,3,0.1), CalcInfo, item)
    c(item,
      "maxinfo"=max(info),
      "locmaxinfo"=unname((which.max(info)-31)/10),
      "cb_sd"=sd(difficulties))
    }))
#saveRDS(itempool, "itempool.RDS")
#itempool=readRDS("itempool.RDS")

#########################################################################

sim=mapply(
  function(numdimensions, cormag, bankinfoshape, calbss ){
      print(paste(numdimensions, cormag, bankinfoshape, calbss ))
      
      simulees=NA
      iteration=1
      while(length(simulees)==1){
      print(paste("iteration:",iteration));
      
      #generate empty matrix for scale-scale correlations
      scaleintercormat=matrix(1,nrow=numdimensions,ncol=numdimensions)

      #generate random scale-scale correlations from a given range
      scaleintercorr=sample(
                      seq(
                        strsplit(as.character(cormag),"-")[[1]][1],
                        strsplit(as.character(cormag),"-")[[1]][2],
                        0.01),
                      (numdimensions^2-numdimensions)/2)
      
      #populate MVN matrix
      scaleintercormat[lower.tri(scaleintercormat)]=scaleintercorr
      scaleintercormat=t(scaleintercormat)
      scaleintercormat[lower.tri(scaleintercormat)]=scaleintercorr

      #sim data
      simulees=try(mvrnorm(n=calbss,mu=rep(0,numdimensions), Sigma=scaleintercormat))
      
      iteration=iteration+1;}
      
      # items=replicate(numdimensions, simplify=FALSE, {
      #   #select item from item pool (1 million items) to suit the information shape
      #   bankinfoshapepts=switch(as.character(bankinfoshape),
      #                             "flat"=round(seq(-3,3,length.out=ni_dim),1),
      #                             "leptokurtic"=round(rnorm(ni_dim,0,0.25),1),
      #                             "skewed"=round(rbeta(ni_dim,2,5),1))
      #   
      #   if(bankinfoshape=="flat"){
      #     bankinfoshapepts=sample(bankinfoshapepts,length(bankinfoshapepts))
      #   } else {
      #     bankinfoshapepts=as.numeric(unlist(
      #       apply(data.frame(sort(table(bankinfoshapepts),decreasing=TRUE)),1,
      #             function(x){rep(x[1],times=x[2])})))}    
      # 
      #   bankinfoshapepts=bankinfoshapepts-min(bankinfoshapepts)
      #   bankinfoshapepts=bankinfoshapepts*(3/max(bankinfoshapepts))
      #   bankinfoshapepts=round(bankinfoshapepts,1)
      #   
      #   #select item from item pool (1 million items) to suit the information shape
      #     items_used=c()
      # 
      #     items=matrix(NA, ncol=ncol(itempool), nrow=length(bankinfoshapepts))
      # 
      #     for(index in 1:length(bankinfoshapepts)){
      #         t=bankinfoshapepts[index]
      #         item=which(itempool[,"locmaxinfo"]==t & !(1:nrow(itempool) %in% items_used))
      #         item=item[which.max(itempool[item,"maxinfo"])]
      #         items_used=c(items_used,item)
      #         items[index,]=itempool[item,]        
      # 
      #     }
      #     colnames(items)=colnames(itempool)
      #     items
      # })
      #     
      #     
      # #items=split(items,sort(rep(1:numdimensions,ni_dim)))
      # 
      # bankinfo=lapply(1:numdimensions, function(dim){
      #           bankinfo=rowSums(
      #               apply(items[[dim]],1,function(i){
      #                 sapply(seq(-3,3,0.1), function(t){CalcInfo(t,i)})}))
      #           names(bankinfo)=seq(-3,3,0.1)
      #           bankinfo
      #           })

#new item bank simulation

thetaquad=round(seq(-3,3,0.1),1)

banksample=split(1:nrow(itempool),rep(1:10,nrow(itempool)/10))

items=lapply(banksample, function(banksample){
  #select item from item pool (1 million items) to suit the information shape
  bankinfoshapedensity=switch(as.character(bankinfoshape),
                          "flat"=rep(1/61, times=length(thetaquad)),
                          "leptokurtic"=dnorm(thetaquad,0,2)/sum(dnorm(thetaquad,0,2)),
                          "skewed"=(dbeta(thetaquad/4+2.5/4,2.5,4)+2.5/4)/(sum(dbeta(thetaquad/4+2.5/4,2.5,4)+2.5/4)))

  
  
  
  itemsused=c()

  bankinfo=rep(0,times=length(thetaquad))
  names(bankinfo)=thetaquad
  
  items=itempool[banksample,]
  iteminfo=apply(items,1,function(i){
    sapply(thetaquad, function(t){CalcInfo(t,i)})})

  #iterate over 'best items'
  
  for(item in 1:ni_dim){
      deviance=numeric(length=ncol(iteminfo))
      bankiteminfo=iteminfo
      for(candidateitem in 1:ncol(iteminfo)){
        bankiteminfo[,candidateitem]=iteminfo[,candidateitem]+bankinfo
        deviance[candidateitem]=
          sum(abs(bankinfoshapedensity-bankiteminfo[,candidateitem]/sum(bankiteminfo[,candidateitem])))
        }
      bestitem=which.min(deviance[!(1:ncol(iteminfo)%in%itemsused)])
      itemsused=c(itemsused,bestitem)
      bankinfo=bankiteminfo[,bestitem]
  }
  list("items"=items[itemsused,], "bankinfo"=bankinfo,"design"=bankinfoshapedensity, "deviance"=deviance)
})

items=items[order(sapply(items, function(x){x$deviance[length(x$deviance)]}),decreasing=FALSE)[1:numdimensions]]

      
      

     calbdata=lapply(1:numdimensions, function(dim){
                sapply(simulees[,dim], function(theta){
                  apply(items[[dim]][["items"]], 1, function(item){
                    sample(1:5, 1, prob=CalcRespProb(theta,unlist(item[1:6])))
                  })
                })
              })

      list("items"=items, #"bankinfo"=bankinfo, "save"=save,
           "simulees"=simulees, "calbdata"=calbdata)
  }, 
design_conditions$dimensions,
design_conditions$intercorrmag,
design_conditions$bankinfoshape,
design_conditions$calbsamplesize,
SIMPLIFY = FALSE
)


saveRDS(sim, "sim.RDS")


sapply(sim, function(i){
  numdim=ncol(i$calbdata)
  
  if(numdim==3){
      dat=t(do.call(rbind, i$calbdata))
      model <- mirt.model('
      F1 = 1-50
      F2 = 51-100
      F3 = 101-150
      COV = F1*F2, F1*F3, F2*F3')
      cmod <- mirt(dat, model)  
    
  }
  
  if(numdim==5){
      dat=t(do.call(rbind, i$calbdata))
      model <- mirt.model('
      F1 = 1-50
      F2 = 51-100
      F3 = 101-150
      F4 = 151-200
      F5 = 201-250
      COV = F1*F2, F1*F3, F1*F4, F1*F5, F2*F3, F2*F4, F2*F5, F3*F4, F3*F5, F4*F5')
      cmod <- mirt(dat, model)    
  }
  
  cmod
  
})


# dat=data.frame(t(do.call(rbind, sim[[1]]$calbdata)))
# for(c in 1:ncol(dat)){dat[,c]=ordered(dat[,c])}

dat=t(do.call(rbind, sim[[95]]$calbdata))
saveRDS(dat,"dat.RDS")

model <- mirt.model('
F1 = 1-50
F2 = 51-100
F3 = 101-150
COV = F1*F2, F1*F3, F2*F3')
cmod <- mirt(dat, model)



#######################
calb=readRDS("calb.RDS")
#plot by fit indices
attributes(calb[[1]])
str(calb[[1]])

calb[[1]]@Fit$BIC #also h2/g2&RMSEA


unlist(coef(calb[[1]])['1'])

do.call(rbind, coef(calb[[1]])[names(coef(calb[[1]]))!="GroupPars"])


BiasRMSE=simplify2array(lapply(1:length(calb), function(design){
    EstParms=t(sapply(coef(calb[[design]])[names(coef(calb[[design]]))!="GroupPars"], function(x){
      
      #b=-d/a
      x[colnames(x) %in% paste0("d",1:4)]=
        (-x[colnames(x) %in% paste0("d",1:4)])/x[x!=0 & colnames(x) %in% paste0("a",1:5)]
          
      ynames=c(paste0("a",1:5),paste0("d",1:4))
      y=rep(NA,times=length(ynames))
      names(y)=ynames
          y[match(colnames(x),names(y))]=x
      names(y)=gsub("d","cb",names(y))
      y
      }))
      
    DesignParms=do.call(rbind,lapply(1:length(sim[[design]]$items), function(dim){
      x=sim[[design]]$items[[dim]]$items[,c("a",paste0("cb",1:4))]
      colnames(x)[colnames(x)=="a"]=paste0("a",dim)
      merge(x,
        data.frame("a1"=0,"a2"=0,"a3"=0, "a4"=0, "a5"=0),
        all.x=TRUE)[,union(names(data.frame("a1"=0,"a2"=0,"a3"=0, "a4"=0, "a5"=0)), colnames(x))]
      
    }))
    
    BiasRMSE=t(sapply(colnames(EstParms), function(col){
      denom=sum(EstParms[,col]!=0)
      if(is.na(denom)){denom=1}
      list(
      "Bias"=sum(EstParms[,col]-DesignParms[,col], na.rm = TRUE)/denom,
      "RMSE"=sqrt(sum((EstParms[,col]-DesignParms[,col])^2, na.rm = TRUE)/denom))
    }))

}), higher=TRUE)


plot()


which(design_conditions$bankinfoshape=="flat")
which(design_conditions$bankinfoshape=="flat")
which(design_conditions$bankinfoshape=="flat")

which(design_conditions$intercorrmag=="0-0.2")

which(design_conditions$dimensions=="3")


colors=rainbow(length(calbsamplesize))
plot(NA, xlim=c(0,1200), ylim=c(0,5))
for(pts in lapply(calbsamplesize, function(ss){which(design_conditions$calbsamplesize == ss)}))
{plotdat=cbind(design_conditions$calbsamplesize[pts[1]],unlist(BiasRMSE[paste0("cb",1:4),"RMSE",pts]))
plotdat[,1]=jitter(plotdat[,1])
  points(plotdat,col=colors[1])
  colors=colors[-1]}

par(mfrow=c(2,5))
for(dim in unique(dimensions)){
  for(a in paste0("a",1:5)){
    boxplot(unlist(BiasRMSE[a,"RMSE",which(design_conditions$dimensions==dim)])~design_conditions$calbsamplesize[which(design_conditions$dimensions==dim)],
            main=paste0("Box Plot of Param RMSE, ",a,"\n ",dim," dimensions"),
            xlab="Calibration Sample Size",
            ylab="RMSE",
            ylim=c(0.4,1.2)
            )  
  }
}

par(mfrow=c(2,5))
for(dim in unique(dimensions)){
  for(a in paste0("a",1:5)){
    boxplot(unlist(BiasRMSE[a,"RMSE",which(design_conditions$dimensions==dim)])~design_conditions$intercorrmag[which(design_conditions$dimensions==dim)],
            main=paste0("Box Plot of Param RMSE, ",a,"\n ",dim," dimensions"),
            xlab="Scale-Scale Correlation",
            ylab="RMSE",
            ylim=c(0.4,1.2))  
  }
}


par(mfrow=c(2,4))
for(dim in unique(dimensions)){
for(cb in paste0("cb",1:4)){
    boxplot(unlist(BiasRMSE[cb,"RMSE",which(design_conditions$dimensions==dim)])~design_conditions$calbsamplesize[which(design_conditions$dimensions==dim)],
            ylim=c(2,4.5),
            main=paste0("Box Plot of Param RMSE, ",cb,"\n ",dim," dimensions"),
            xlab="Calibration Sample Size",
            ylab="RMSE")  
  }
}


##########################################################################


par(mfrow=c(2,5))
for(dim in unique(dimensions)){
  for(a in paste0("a",1:5)){
    boxplot(unlist(BiasRMSE[a,"RMSE",which(design_conditions$dimensions==dim & design_conditions$bankinfoshape=="skewed")])~design_conditions$calbsamplesize[which(design_conditions$dimensions==dim & design_conditions$bankinfoshape=="skewed")],
            main=paste0("Box Plot of Param RMSE, ",a,"\n ",dim," dimensions"),
            xlab="Calibration Sample Size",
            ylab="RMSE",
            ylim=c(0.4,1.2))  
  }
}

par(mfrow=c(2,5))
for(dim in unique(dimensions)){
  for(a in paste0("a",1:5)){
    boxplot(unlist(BiasRMSE[a,"RMSE",which(design_conditions$dimensions==dim  & design_conditions$bankinfoshape=="skewed")])~design_conditions$intercorrmag[which(design_conditions$dimensions==dim & design_conditions$bankinfoshape=="skewed")],
            main=paste0("Box Plot of Param RMSE, ",a,"\n ",dim," dimensions"),
            xlab="Scale-Scale Correlation",
            ylab="RMSE",
            ylim=c(0.4,1.2))  
  }
}

par(mfrow=c(2,4))
for(dim in unique(dimensions)){
for(cb in paste0("cb",1:4)){
    boxplot(unlist(BiasRMSE[cb,"RMSE",which(design_conditions$dimensions==dim & design_conditions$bankinfoshape=="skewed")])~design_conditions$calbsamplesize[which(design_conditions$dimensions==dim & design_conditions$bankinfoshape=="skewed" )],
            ylim=c(2,4),
            main=paste0("Box Plot of Param RMSE, ",cb,"\n ",dim," dimensions"),
            xlab="Calibration Sample Size",
            ylab="RMSE")  
  }
}











#parm recovery, rmsea & bias




temp=sim.hierarchical()

ni=100
nf=4

Med_r=sim.hierarchical(
  gload = rep(0.9,nf),
  fload=matrix(
          c(sample(seq(0.4,0.9,0.01),ni/nf),rep(0,ni),
            sample(seq(0.4,0.9,0.01),ni/nf),rep(0,ni),
            sample(seq(0.4,0.9,0.01),ni/nf),rep(0,ni),
            sample(seq(0.4,0.9,0.01),ni/nf)), ncol=nf),
  n=100, categorical = TRUE, low = 1, high = 5
  )

#process
1)simulate data for various conditions (cycle through mapply & expand.grid)
2)fit confirmatory mirt model, using output (sampled) FA loadings (items assigned to highest factor-item loading)
3)cat sim
```


 
 
